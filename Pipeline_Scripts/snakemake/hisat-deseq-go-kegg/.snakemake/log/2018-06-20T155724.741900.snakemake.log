Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	2	as
	3

rule as:
    input: outData/as/merge_UHR.gtf
    output: outData/as/UHR_event_count.txt
    jobid: 18
    wildcards: condition=UHR

    Error in rule as:
        jobid: 18
        output: outData/as/UHR_event_count.txt

RuleException:
CalledProcessError in line 34 of /home/liyubing/analysis/7_snakemake/hisat-deseq-go-kegg/pro1/rules/stringtie_as.smk:
Command ' set -euo pipefail;  
                 astalavista -t asta --threads 10 -i outData/as/merge_UHR.gtf
                 gunzip merged_UHR_sorted.gtf_astalavista.gtf.gz
                 awk -f scripts/as.awk merged_UHR_sorted.gtf_astalavista.gtf > outData/as/UHR_event_count.txt ' returned non-zero exit status 1.
  File "/home/liyubing/analysis/7_snakemake/hisat-deseq-go-kegg/pro1/rules/stringtie_as.smk", line 34, in __rule_as
  File "/data1/software/miniconda2/envs/py3/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/liyubing/analysis/7_snakemake/hisat-deseq-go-kegg/pro1/.snakemake/log/2018-06-20T155724.741900.snakemake.log
